{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import scipy\n",
    "import scipy.misc\n",
    "from lxml import etree\n",
    "\n",
    "# for calling the haarcascade xml file\n",
    "cascPath = \"haarcascade_frontalface_default.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter the location for creating a new database\n",
    "new_database = r'D:\\face detection and recognition\\alok\\FaceVOC' \n",
    "if not os.path.exists(new_database):\n",
    "    os.makedirs(new_database)\n",
    "count = 0\n",
    "ii=0\n",
    "#enter the number of classes ( Here the number of videos named as videox (where x should be 0,1,2,3...num_class-1)\n",
    "# should be equal to number of classes,where each video bears each class)\n",
    "num_class=4\n",
    "#enter the name of the classes\n",
    "name_class=[\"name1\",\"name2\",\"name3\",\"name4\"]\n",
    "for ii in range(0,num_class):\n",
    "    \n",
    "    #Enter the address of the video location or enter 0 for using webcam usage,\n",
    "    # the program can be modified accordingly by closing the present webcam window and opening a new one at the end of each loop.\n",
    "    vidcap = cv2.VideoCapture('D:\\\\face detection and recognition\\\\alok\\\\videos\\\\video%d.mp4'%ii)\n",
    "    success,image = vidcap.read()\n",
    "    \n",
    "    success = True\n",
    "    #count+=count\n",
    "    while success:\n",
    "        #enter the factor by which the width and height have to be divided. For keeping original image, keep factor as 1\n",
    "        factor=2.56\n",
    "        a=int(image.shape[1]/2.56)  \n",
    "        b=int(image.shape[0]/2.56)\n",
    "    \n",
    "        frame=cv2.resize(image, (a,b))\n",
    "        \n",
    "        #create the folder where the image files has to be saved\n",
    "        destinationfolder = os.path.join(new_database,\"JPEGImages\")\n",
    "        if not os.path.exists(destinationfolder):\n",
    "            os.makedirs(destinationfolder)\n",
    "        cv2.imwrite(os.path.join(destinationfolder,\"Image%d.jpg\" % count), frame)     # save frame as JPEG file\n",
    "  \n",
    "        # divide the images for training, test and validation\n",
    "        destinationdivide = os.path.join(new_database,\"Main\")\n",
    "        if not os.path.exists(destinationdivide):\n",
    "            os.makedirs(destinationdivide)\n",
    "        \n",
    "\n",
    "        x=None\n",
    "        y=None\n",
    "        w=None\n",
    "        h=None              \n",
    "        # Obtain coordinates of face\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = faceCascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), \n",
    "                                        flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        \n",
    "        \n",
    "        # Draw a rectangle around the faces\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "        if (x!=None) and (y!=None) and (h!=None) and (w!=None):\n",
    "            f1= (\"Image%d\\n\" %count)\n",
    "            \n",
    "            # the number of images you need for training validation etc .. can be varied here by varying the number after % \n",
    "            # as per your choice\n",
    "            \n",
    "            \n",
    "            \n",
    "            if (count % 2) == 0:\n",
    "                with open(os.path.join(destinationdivide,\"trainval.txt\"),\"a\") as ufile1: \n",
    "                        ufile1.write(f1)\n",
    "    \n",
    "            else:\n",
    "                with open(os.path.join(destinationdivide,\"test.txt\"), \"a\") as ufile2: \n",
    "                        ufile2.write(f1)\n",
    "            \n",
    "            if(count % 3)== 0:\n",
    "                with open(os.path.join(destinationdivide,\"val.txt\"), \"a\") as ufile3: \n",
    "                        ufile3.write(f1)     \n",
    "            else:\n",
    "                with open(os.path.join(destinationdivide,\"train.txt\"), \"a\") as ufile4: \n",
    "                        ufile4.write(f1)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        # write to xml file\n",
    "            destination_annote= os.path.join(new_database,\"Annotations\")\n",
    "            if not os.path.exists(destination_annote):\n",
    "                os.makedirs(destination_annote)\n",
    "            outFile = open(os.path.join(destination_annote,'Image%d.xml' %count), 'wb')\n",
    "    \n",
    "            page = etree.Element('Annotations')\n",
    "\n",
    "        #use the etree.ElementTree() constructor to make a new document tree, using our html element as its root:\n",
    "\n",
    "            doc = etree.ElementTree(page)\n",
    "\n",
    "        #  use etree.SubElement() constructor for adding new child elements to our document. \n",
    "\n",
    "\n",
    "            folder = etree.SubElement(page, 'folder')\n",
    "            folder.text='JPEGImages'\n",
    "\n",
    "            filename = etree.SubElement(page, 'filename')\n",
    "            filename.text='Image%d.jpg'%count\n",
    "\n",
    "            path = etree.SubElement(page, 'path')\n",
    "            path.text=destinationfolder\n",
    "\n",
    "            source=etree.SubElement(page, 'source')\n",
    "            database=etree.SubElement(source, 'database')\n",
    "            database.text='RECognVOC'\n",
    "\n",
    "            size=etree.SubElement(page, 'size')\n",
    "            width=etree.SubElement(size, 'width')\n",
    "            width.text=str(a)\n",
    "            height=etree.SubElement(size, 'height')\n",
    "            height.text=str(b)  \n",
    "            depth=etree.SubElement(size, 'depth')\n",
    "            depth.text='3'\n",
    "\n",
    "            segmented=etree.SubElement(page, 'segmented')\n",
    "            segmented.text='0'\n",
    "\n",
    "            object=etree.SubElement(page, 'object')\n",
    "            name=etree.SubElement(object, 'name')   \n",
    "        \n",
    "            name.text=name_class[ii]      \n",
    "                                       \n",
    "            pose=etree.SubElement(object, 'pose')\n",
    "            pose.text='unspecified'\n",
    "            truncated=etree.SubElement(object, 'truncated')\n",
    "            truncated.text='0'\n",
    "            difficult=etree.SubElement(object, 'difficult')\n",
    "            difficult.text='0'\n",
    "            bndbox=etree.SubElement(object, 'bndbox')\n",
    "            xmin=etree.SubElement(bndbox, 'xmin')\n",
    "            xmin.text=str(x)\n",
    "            ymin=etree.SubElement(bndbox, 'ymin')\n",
    "            ymin.text=str(y)\n",
    "            xmax=etree.SubElement(bndbox, 'xmax')\n",
    "            xmax.text=str(x+w)\n",
    "            ymax=etree.SubElement(bndbox, 'ymax')\n",
    "            ymax.text=str(y+h)\n",
    "            doc.write(outFile)\n",
    "\n",
    "        success,image = vidcap.read()\n",
    "        count += 1  \n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
